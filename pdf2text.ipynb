{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import codecs\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "import pytesseract\n",
    "from PIL import Image, ImageEnhance, ImageFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCR - PDF2Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "pages = convert_from_path('test.pdf', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for page in pages:\n",
    "    page.save('out'+str(counter)+'.jpg', 'JPEG')\n",
    "    counter +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "textl = []\n",
    "\n",
    "for i in range(counter):\n",
    "    \n",
    "    im = Image.open(\"out\"+str(i)+\".jpg\") # the second one \n",
    "    im = im.filter(ImageFilter.MedianFilter())\n",
    "    enhancer = ImageEnhance.Contrast(im)\n",
    "    im = enhancer.enhance(2)\n",
    "    im = im.convert('1')\n",
    "    im.save('temp2.jpg')\n",
    "    text = pytesseract.image_to_string(Image.open('temp2.jpg'))\n",
    "    textl.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "\n",
    "def preprocess(sent):\n",
    "\n",
    "    sent = re.sub('[!@$#]', '', sent)\n",
    "    sent = re.sub(\n",
    "        r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', sent)\n",
    "    sent = re.sub(r\"com\\S+\", \"\", sent)\n",
    "    sent = re.sub('\\s+',' ',sent)\n",
    "    sent = sent.strip()\n",
    "    sent = unicodedata.normalize(\"NFKD\", sent)\n",
    "    #sent = nltk.word_tokenize(sent)\n",
    "\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing collected tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = preprocess(textl[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.2 Multilevel Indexes 18.2 Multilevel Indexes The indexing schemes we have described thus far involve an ordered index file. A binary search is applied to the index to locate pointers to a disk block or to a record (or records) in the file having a specific index field value. A binary search requires approximately (log,b,) block accesses for an index with b, blocks because each step of the algorithm reduces the part of the index file that we continue to search by a factor of 2. This is why we take the log function to the base 2. The idea behind a multilevel index is to reduce the part of the index that we continue to search by Of, the blocking factor for the index, which is larger than 2. Hence, the search space is reduced much faster. The value bfr, is called the fan-out of the multilevel index, and we will refer to it by the symbol fo. Whereas we divide the record search space into two halves at each step during a binary search, we divide it n-ways (where n = the fan-out) at each search step using the multilevel index. Searching a multilevel index requires approximately (log,.b) block accesses, which is a substantially smaller number than for a binary search if the fan-out is larger than 2. In most cases, the fan-out is much larger than 2. A multilevel index considers the index file, which we will now refer to as the first (or base) level of a multilevel index, as an ordered file with a distinct value for each K(1). Therefore, by considering the first-level index file as a sorted data file, we can create a primary index for the first level; this index to the first level is called the second level of the multilevel index. Because the second level is a primary index, we can use block anchors so that the second level has one entry for each block of the first level. The blocking factor bfr, for the second level—and for all subsequent levels—is the same as that for the first-level index because all index entries are the same size; each has one field value and one block address. If the first level has r, entries, and the blocking factor—which is also the fan-out—for the index is bfr, = fo, then the first level needs [ (r,/ fo) | blocks, which is therefore the number of entries r, needed at the second level of the index. We can repeat this process for the second level. The third level, which is a primary index for the second level, has an entry for each second-level block, so the number of third-level entries is r, = [ (r,/fo) |. Notice that we require a second level only if the first level needs more than one block of disk storage, and, similarly, we require a third level only if the second level needs more than one block. We can repeat the preceding process until all the entries of some index level t fit in a single block. This block at the tth level is called the top index level.* Each level reduces the number of entries at the previous level by a factor of fo—the index fan-out—so we can use the formula 1 < (r,/((fo)*)) to calculate t. Hence, a multilevel index with r, first-level entries will have approximately t levels, where t = [ (log, (r,)) | When searching the “The numbering scheme for index levels used here is the reverse of the way levels are defined for tree data structures. In tree data structures, t is referred to as level O (zero), t— 1 is level 1, and so on. 643\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
